{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#CV Theory Assignment 11\n",
        "##Name := Yash Bhaskar Narkhede"
      ],
      "metadata": {
        "id": "V4ldtg2c4gdm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. What do REGION PROPOSALS entail?\n",
        "\n",
        "Ans: Region Proposals are a type of computer vision algorithm that are used to identify and extract potential regions of interest in an image or video. These regions are then used to segment the image or video into different areas of interest. The regions are generated through a combination of low-level image features, such as edges and color, as well as high-level semantic information. Region Proposals can be used to detect objects, faces, and text in images and videos.\n",
        "\n",
        "#2. What do you mean by NON-MAXIMUM SUPPRESSION? (NMS)\n",
        "\n",
        "Ans: Non-maximum suppression (NMS) is a computer vision technique used to reduce the number of detected objects in an image by removing redundant or overlapping detections. It works by comparing the maximum detection score at each location in the image and discarding any detections with a score below a certain threshold. NMS can help reduce false positives and improve accuracy in object detection tasks.\n",
        "\n",
        "#3. What exactly is mAP?\n",
        "\n",
        "Ans: mAP stands for mean Average Precision, and it is a metric used to measure the accuracy of object detection algorithms. It is computed by averaging the precision of a model at different recall values, which represents the proportion of objects detected in the image. mAP can also be used to compare different models and determine which one is the most accurate.\n",
        "\n",
        "#4. What is a frames per second (FPS)?\n",
        "\n",
        "Ans: FPS is a measure of the number of individual frames (or images) that compose a single second of video. It is commonly used to measure the frame rate achieved by a video camera, display, or other device. Computer vision applications often require high frame rates to capture and analyze events as they occur, so FPS is an important metric for measuring the performance of these systems.\n",
        "\n",
        "#5. What is an IOU (INTERSECTION OVER UNION)?\n",
        "\n",
        "Ans: IOU, or Intersection Over Union, is a metric used to evaluate the accuracy of an object detection algorithm. It is the ratio of the area of overlap between the predicted bounding box and the ground truth bounding box to the total area of the two bounding boxes. A higher IOU indicates a better match between the predicted and ground truth bounding boxes. This metric is commonly used in computer vision tasks such as object detection, image segmentation, and image classification.\n",
        "\n",
        "#6. Describe the PRECISION-RECALL CURVE (PR CURVE)\n",
        "\n",
        "Ans: The precision-recall curve (PR curve) is a graphical plot used to evaluate the accuracy of a model in a binary classification task. It is a plot of the precision (positive predictive value) against the recall (sensitivity) of the model. The PR curve is used to measure the trade-off between a modelâ€™s precision and recall. The higher the precision and recall, the better the model is at accurately predicting the positive class. The PR curve can also be used to compare different models. The model with the higher area under the curve (AUC) is generally considered to be the more accurate model.\n",
        "\n",
        "#7. What is the term \"selective search\"?\n",
        "\n",
        "Ans: Selective search is a method of object detection in computer vision that involves searching an image for objects by iteratively considering a large set of regions. The goal of selective search is to rapidly identify regions in an image that are likely to contain objects, and then to refine these regions to create a set of object proposals.\n",
        "\n",
        "#8. Describe the R-CNN model's four components.\n",
        "\n",
        "Ans: 1. Selective Search: This is the process of proposing potential regions in an image that could contain an object of interest.\n",
        "\n",
        "Region Proposal Network (RPN): This is a convolutional neural network that takes in the proposed regions from Selective Search and outputs a set of refined proposals.\n",
        "\n",
        "Convolutional Neural Network (CNN): This is a deep learning architecture that takes in the refined proposals from the RPN and classifies them into different classes.\n",
        "\n",
        "Bounding Box Regression: This is a technique used to adjust the coordinates of the predicted bounding boxes so that they more accurately fit the objects they contain.\n",
        "\n",
        "#9. What exactly is the Localization Module?\n",
        "\n",
        "Ans: The Localization Module in computer vision is a tool used to locate objects in an image or video. It uses features such as color, shape, and texture to detect objects in an image. It also allows for recognition of objects in different locations in the image. The Localization Module is used in applications such as object tracking, facial recognition, and robotics.\n",
        "\n",
        "#10. What are the R-CNN DISADVANTAGES?\n",
        "\n",
        "Ans: The main disadvantages of R-CNN are:\n",
        "\n",
        "It is slow due to the multiple steps involved in the detection process.\n",
        "\n",
        "It is computationally expensive.\n",
        "\n",
        "There is a lack of scalability, as each region proposal needs to be re-evaluated with each new input image.\n",
        "\n",
        "It is relatively challenging to implement, as it requires deep learning expertise to properly tune the network.\n",
        "\n",
        "It does not produce satisfactory results in scenarios with large objects or objects with a small number of pixels.\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "JXbdzyrv4lc6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfFUk2YO4fu4"
      },
      "outputs": [],
      "source": []
    }
  ]
}